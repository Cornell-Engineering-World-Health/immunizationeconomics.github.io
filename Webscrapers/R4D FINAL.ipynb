{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webscraping complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For this webscraper, the job description and requirements were combined into the same cell because they were not \n",
    "easily separated from the site's html. \n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://r4d.csod.com/ats/careersite/search.aspx?site=2&c=r4d'\n",
    "\n",
    "with requests.Session() as s: \n",
    "    r = s.get(url)\n",
    "    src = r.content \n",
    "    soup = bs(src)\n",
    "    soup.prettify()\n",
    "\n",
    "    table2 = soup.find(\"table\", class_ = 'results-table').find(\"tbody\").find_all(\"tr\")\n",
    "    \n",
    "    root_url = \"https://r4d.csod.com/ats/careersite/\"\n",
    "    \n",
    "    page_url = []     \n",
    "    job_position = [] \n",
    "    location = []     \n",
    "    des_and_req = []  \n",
    "    Immunization = [] \n",
    "    Economics = []    \n",
    "    \n",
    "    allLinks = []\n",
    "    allJobNames = []\n",
    "    allLocations = []\n",
    "    locationDataList = []\n",
    "    \n",
    "    for data in table2:\n",
    "        job = data.find('a').text\n",
    "        allJobNames.append(job)\n",
    "        \n",
    "        link = data.find('a')['href']\n",
    "        complete_url = root_url + link\n",
    "        allLinks.append(complete_url)\n",
    "    \n",
    "        locationData = data.find('span', class_ = \"FieldValue\").getText()\n",
    "        locationDataList = locationData.split(\" | \")\n",
    "        locationString = locationDataList[2]\n",
    "        locationString = locationString.replace(\"\\xa0)\",\"\")\n",
    "        moreString = \"\"\n",
    "        if \"More\" in locationString:\n",
    "            moreString = data.find('span', class_ = \"FieldValue\").find('a')['onclick']\n",
    "            moreString = moreString.replace(\"showAllLocations('\", \"\").replace(\"','\", \"\\n\").replace(\"','\", \"\\n\").replace(\"\\\\u003cbr/\\\\u003e\", \", \")\n",
    "        moreString = \"\\nMore - \" + moreString\n",
    "        locationString = locationString.replace(\"More\", moreString)\n",
    "        allLocations.append(locationString)\n",
    "    \n",
    "    \n",
    "    index = 0\n",
    "    for page in allLinks:\n",
    "        result = s.get(page)\n",
    "        page_source = result.content\n",
    "        soup = bs(page_source) \n",
    "        soup.prettify()\n",
    "\n",
    "        \n",
    "        for script in soup(['script','style']):\n",
    "            script.decompose()\n",
    "        strips = list(soup.stripped_strings)\n",
    "        strips = str(strips)\n",
    "\n",
    "    \n",
    "        immunization = ['Immunization', 'immunisation', 'vaccine', 'vaccines','vaccine-preventable diseases', 'vpd outbreak',\n",
    "            'immunization campaign', 'SIA','supplemental immunization act ivities', 'cold chain', 'GAVI','shigella', 'cholera',\n",
    "            'bcg', 'dtp', 'dpt', 'measles', 'influenza', 'conjugate vaccine']\n",
    "\n",
    "        economics = ['Economics','expenditure tracking', 'financing', \n",
    "            'value for vaccination' , 'costing', 'economic analysis','costs' , 'equity', 'cost effectiveness', 'cost-effectiveness', \n",
    "            'cost benefit analysis', 'benefit-cost analysis','cost utility analysis','budget impact analysis' , 'budget' , 'budgeting' , \n",
    "            'GAVI','funding gap','fiscal']\n",
    "\n",
    "        imm_result = any(ele in strips for ele in immunization)\n",
    "        ec_result = any(ele in strips for ele in economics)\n",
    "        \n",
    "        if imm_result or ec_result:\n",
    "            if imm_result: Immunization.append('True')\n",
    "            else: Immunization.append('False')\n",
    "            if ec_result: Economics.append('True')\n",
    "            else: Economics.append('False')\n",
    "            \n",
    "            page_url.append(page) \n",
    "            job_position.append(allJobNames[index])\n",
    "            location.append(allLocations[index])\n",
    "        \n",
    "            job_data = soup.find('div', class_='cs-atscs-jobdet-rtpane')\n",
    "\n",
    "            desReqList= [desReqList.text.replace(\"\\n\",\" \").replace(\"      \", \" \") for desReqList in job_data.select('p, ul li')]\n",
    "            desReqList.pop()\n",
    "            popped = desReqList.pop(0)\n",
    "\n",
    "            job_text = \"\"\n",
    "            for elem in desReqList:\n",
    "                job_text += elem + \"\\n\"\n",
    "                job_text = job_text.replace(\"\\xa0\",\" \")\n",
    "            des_and_req.append(job_text)\n",
    "        index += 1\n",
    "        \n",
    "        \n",
    "DataFrame = pd.DataFrame() \n",
    "DataFrame['Page Url']= page_url \n",
    "DataFrame['Job']= job_position \n",
    "DataFrame['Location'] = location\n",
    "DataFrame['Description and Requirements'] = des_and_req\n",
    "DataFrame['Immunization'] = Immunization\n",
    "DataFrame['Economics'] = Economics\n",
    "\n",
    "Data = DataFrame.drop_duplicates() \n",
    "Data.to_csv(\"R4D_Data.csv\")\n",
    "\n",
    "print('Webscraping complete')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
