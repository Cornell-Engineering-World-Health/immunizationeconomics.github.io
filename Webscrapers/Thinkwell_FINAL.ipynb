{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/Users/alisonlandry/Library/Caches/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: selenium in /Applications/anaconda3/lib/python3.7/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /Applications/anaconda3/lib/python3.7/site-packages (from selenium) (1.25.8)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Applications/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/Users/alisonlandry/Library/Caches/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Requirement already satisfied: webdriver_manager in /Applications/anaconda3/lib/python3.7/site-packages (3.2.2)\n",
      "Requirement already satisfied: configparser in /Applications/anaconda3/lib/python3.7/site-packages (from webdriver_manager) (5.0.1)\n",
      "Requirement already satisfied: requests in /Applications/anaconda3/lib/python3.7/site-packages (from webdriver_manager) (2.22.0)\n",
      "Requirement already satisfied: crayons in /Applications/anaconda3/lib/python3.7/site-packages (from webdriver_manager) (0.4.0)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Applications/anaconda3/lib/python3.7/site-packages (from requests->webdriver_manager) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Applications/anaconda3/lib/python3.7/site-packages (from requests->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Applications/anaconda3/lib/python3.7/site-packages (from requests->webdriver_manager) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.7/site-packages (from requests->webdriver_manager) (2019.11.28)\n",
      "Requirement already satisfied: colorama in /Applications/anaconda3/lib/python3.7/site-packages (from crayons->webdriver_manager) (0.4.3)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Applications/anaconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n",
      "[WDM] - Driver [/Users/alisonlandry/.wdm/drivers/chromedriver/mac64/89.0.4389.23/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "6\n",
      "6\n",
      "Webscraping complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For this webscraper, the job description and requirements were combined into the same cell because they were not \n",
    "easily separated from the site's html. \n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from selenium import webdriver\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from time import sleep\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "\n",
    "url = 'https://thinkwell.global/work-for-us/our-vacancies/'\n",
    "driver.get(url)\n",
    "\n",
    "with requests.Session() as s: \n",
    "    r = s.get(url)\n",
    "    src = driver.page_source\n",
    "    soup = bs(src)\n",
    "    soup.prettify()\n",
    "    \n",
    "    rootUrl = \"https://apply.workable.com/thinkwell\"\n",
    "    \n",
    "    pageUrl = []     \n",
    "    jobPosition = [] \n",
    "    location = []     \n",
    "    des_and_req = []  \n",
    "    ImmEcs = []\n",
    "    organization = []   \n",
    "    \n",
    "    allLinks = []\n",
    "    allJobNames = []\n",
    "    \n",
    "    data = soup.find_all('h3', class_='whr-title')\n",
    "    \n",
    "    for nameLink in data:\n",
    "        link = nameLink.find('a')['href']\n",
    "        allLinks.append(link)\n",
    "        \n",
    "        name = nameLink.find('a').text\n",
    "        allJobNames.append(name)\n",
    "\n",
    "        \n",
    "    jobIndex = 0\n",
    "    for page in allLinks:\n",
    "        driver.get(page)\n",
    "        pageSource = driver.page_source\n",
    "        soup = bs(pageSource) \n",
    "        soup.prettify()\n",
    "\n",
    "        for script in soup(['script','style']):\n",
    "            script.decompose()\n",
    "        strips = list(soup.stripped_strings)\n",
    "        strips = str(strips)\n",
    "                \n",
    "        immunization = ['Immunization', 'immunisation', 'vaccine', 'vaccines','vaccine-preventable diseases', 'vpd outbreak',\n",
    "            'immunization campaign', 'SIA','supplemental immunization activities', 'cold chain', 'GAVI','shigella', 'cholera',\n",
    "            'bcg', 'dtp', 'dpt', 'measles', 'influenza', 'conjugate vaccine']\n",
    "\n",
    "        economics = ['Economics','expenditure tracking', 'financing', \n",
    "            'value for vaccination' , 'costing', 'economic analysis','costs' , 'equity', 'cost effectiveness', 'cost-effectiveness', \n",
    "            'cost benefit analysis', 'benefit-cost analysis','cost utility analysis','budget impact analysis' , 'budget' , 'budgeting' , \n",
    "            'GAVI','funding gap','fiscal']\n",
    "\n",
    "        imm_result = any(ele in strips for ele in immunization)\n",
    "        ec_result = any(ele in strips for ele in economics)\n",
    "        \n",
    "        \n",
    "        if imm_result or ec_result:\n",
    "            if (imm_result and ec_result): ImmEcs.append('Both')\n",
    "            elif imm_result: ImmEcs.append('Immunization')\n",
    "            else: ImmEcs.append('Economics')\n",
    "                \n",
    "            descriptionString = \"\"\n",
    "            requirementsString = \"\"\n",
    "            desReqString = \"\"\n",
    "            \n",
    "            locationList = soup.find_all(\"p\", class_=\"job-details-styles__details--11P0z job-styles__headerDetails--1HMvu\")\n",
    "            for col in locationList: \n",
    "                if \"job-location\" in str(col): location.append(col.text)\n",
    "             \n",
    "            strongTextDes = \"\"\n",
    "            descriptionCode = soup.find(\"div\", class_=\"job-preview-styles__description--2BkR3\")\n",
    "            strongCodeDes = descriptionCode.find_all(\"strong\")\n",
    "            for strong in strongCodeDes:\n",
    "                strongTextDes = \"DELETE\" + strong.text + \"DELETE\"\n",
    "                if \"YOU ARE\" not in strongTextDes and \"OVERVIEW\" not in strongTextDes: strong.replaceWith(strongTextDes)\n",
    "            descriptionString = descriptionString + descriptionCode.get_text(separator=\"\\n\").replace(\"      \", \" \").replace(\"DELETE\\n\", \"\").replace(\"\\nDELETE\", \"\").replace(\"DELETE\", \"\").replace(\"\\n,\", \",\")\n",
    "            desReqString = desReqString + descriptionString\n",
    "            \n",
    "            strongTextRes = \"\"\n",
    "            requirementsCode = soup.find(\"div\", class_=\"job-preview-styles__requirements--2kg4_\")\n",
    "            if requirementsCode != None: \n",
    "                strongCodeRes = requirementsCode.find_all(\"strong\")\n",
    "                for strong in strongCodeRes:\n",
    "                    strongTextRes = \"DELETE\" + strong.text + \"DELETE\"\n",
    "                    if \"YOU ARE\" not in strongTextRes and \"OVERVIEW\" not in strongTextRes: strong.replaceWith(strongTextRes)\n",
    "                requirementsString = requirementsString + requirementsCode.get_text(separator=\"\\n\").replace(\"      \", \" \").replace(\"DELETE\\n\", \"\").replace(\"\\nDELETE\", \"\").replace(\"DELETE\", \"\").replace(\"\\n,\", \",\")\n",
    "\n",
    "            desReqString = desReqString + \"\\n\" + requirementsString\n",
    "            des_and_req.append(desReqString)\n",
    "        \n",
    "            pageUrl.append(page)\n",
    "            jobPosition.append(allJobNames[jobIndex])\n",
    "            \n",
    "            organization.append('Thinkwell')\n",
    "            \n",
    "        jobIndex += 1\n",
    "        \n",
    "        \n",
    "print(len(location))\n",
    "print(len(pageUrl))\n",
    "DataFrame = pd.DataFrame() \n",
    "DataFrame['Page Url']= pageUrl \n",
    "DataFrame['Job']= jobPosition \n",
    "DataFrame['Location'] = location\n",
    "DataFrame['Description and Requirements'] = des_and_req\n",
    "DataFrame['ImmEcs'] = ImmEcs\n",
    "DataFrame['Organization'] = organization\n",
    "\n",
    "Data = DataFrame.drop_duplicates() \n",
    "Data.to_csv(\"Thinkwell_Data.csv\")\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print('Webscraping complete')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
