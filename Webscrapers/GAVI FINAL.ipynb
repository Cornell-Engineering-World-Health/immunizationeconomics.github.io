{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (3.141.0)\n",
      "Requirement already satisfied: urllib3 in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from selenium) (1.25.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (3.2.2)\n",
      "Requirement already satisfied: configparser in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (5.0.1)\n",
      "Requirement already satisfied: requests in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (2.24.0)\n",
      "Requirement already satisfied: crayons in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from webdriver_manager) (0.4.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from requests->webdriver_manager) (1.25.9)\n",
      "Requirement already satisfied: colorama in /Users/hur712/opt/anaconda3/lib/python3.8/site-packages (from crayons->webdriver_manager) (0.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 87.0.4280\n",
      "[WDM] - Get LATEST driver version for 87.0.4280\n",
      "[WDM] - Driver [/Users/hur712/.wdm/drivers/chromedriver/mac64/87.0.4280.20/chromedriver] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Webscraping complete\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "from selenium import webdriver\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "browser = webdriver.Chrome(ChromeDriverManager().install(), options=options)\n",
    "\n",
    "url = 'https://www.gavi.org/work-with-us/vacancies'\n",
    "browser.get(url)\n",
    "\n",
    "iframe = browser.find_element_by_xpath(\"//iframe[@src='/iframes/careers/']\");\n",
    "browser.switch_to.frame(iframe)\n",
    "\n",
    "# switch to the nested frame with table of job openings\n",
    "iframe2 = browser.find_element_by_xpath(\"//iframe[@src='https://gavialliancecareers.secure.force.com/recruit/fRecruit__ApplyJobList?portal=Global']\");\n",
    "iframe2Url = iframe2.get_attribute(\"src\")\n",
    "browser.switch_to.frame(iframe2);\n",
    "\n",
    "\n",
    "with requests.Session() as s: \n",
    "    r = s.get(iframe2Url)\n",
    "    src = r.content \n",
    "    soup = bs(src)\n",
    "    soup.prettify()\n",
    "\n",
    "    rootUrl = \"https://gavialliancecareers.secure.force.com\"\n",
    "    \n",
    "    pageUrl = []     \n",
    "    jobPosition = [] \n",
    "    location = []     \n",
    "    description = []  \n",
    "    requirements = [] \n",
    "    Immunization = [] \n",
    "    Economics = []    \n",
    "    \n",
    "    allLinks = []\n",
    "    allJobNames = []\n",
    "    allLocations = []\n",
    "    \n",
    "    table = soup.find(\"table\").find(\"tbody\").find_all(\"tr\")\n",
    "    \n",
    "    nameLinkList = []\n",
    "    for data in table:\n",
    "        allTd = data.find_all(\"td\")\n",
    "        nameLinkList.append(allTd[1])\n",
    "        allLocations.append(allTd[2].text)\n",
    "\n",
    "    for nameLink in nameLinkList:\n",
    "        name = nameLink.find('a').text\n",
    "        allJobNames.append(name)\n",
    "        \n",
    "        link = nameLink.find('a')['href']\n",
    "        completeUrl = rootUrl + link\n",
    "        allLinks.append(completeUrl)\n",
    "\n",
    "        \n",
    "    jobIndex = 0\n",
    "    for page in allLinks:\n",
    "        result = s.get(page)\n",
    "        pageSource = result.content\n",
    "        soup = bs(pageSource) \n",
    "        soup.prettify()\n",
    "\n",
    "        for script in soup(['script','style']):\n",
    "            script.decompose()\n",
    "        strips = list(soup.stripped_strings)\n",
    "        strips = str(strips)\n",
    "        \n",
    "        \n",
    "        leftColTable = soup.find(\"table\").find(\"table\", class_ = 'detailList').find_all(\"label\")\n",
    "        rightColTable = soup.find(\"table\").find_all(\"table\", class_ = 'htmlDetailElementTable')\n",
    "\n",
    "        headingColList = []\n",
    "        descrAndReqRowNum = 7\n",
    "        for heading in leftColTable:\n",
    "            name = heading.text.replace(\"\\n\", \"\")\n",
    "            headingColList.append(name)\n",
    "        headingColList = headingColList[descrAndReqRowNum:]\n",
    "\n",
    "        \n",
    "        immunization = ['Immunization', 'immunisation', 'vaccine', 'vaccines','vaccine-preventable diseases', 'vpd outbreak',\n",
    "            'immunization campaign', 'SIA','supplemental immunization activities', 'cold chain', 'GAVI','shigella', 'cholera',\n",
    "            'bcg', 'dtp', 'dpt', 'measles', 'influenza', 'conjugate vaccine']\n",
    "\n",
    "        economics = ['Economics','expenditure tracking', 'financing', \n",
    "            'value for vaccination' , 'costing', 'economic analysis','costs' , 'equity', 'cost effectiveness', 'cost-effectiveness', \n",
    "            'cost benefit analysis', 'benefit-cost analysis','cost utility analysis','budget impact analysis' , 'budget' , 'budgeting' , \n",
    "            'GAVI','funding gap','fiscal']\n",
    "\n",
    "        immResult = any(ele in strips for ele in immunization)\n",
    "        ecResult = any(ele in strips for ele in economics)\n",
    "        \n",
    "        if immResult or ecResult:\n",
    "            if immResult: Immunization.append('True')\n",
    "            else: Immunization.append('False')\n",
    "            if ecResult: Economics.append('True')\n",
    "            else: Economics.append('False')\n",
    "                \n",
    "            localTableIndex = 0\n",
    "            descriptionString = \"\"\n",
    "            requirementsString = \"\"\n",
    "            jobString = \"\"\n",
    "            for jobData in rightColTable:\n",
    "                jobInfo = jobData.find('div')\n",
    "                jobString += str(jobInfo)\n",
    "                if \"<li>\" in jobString: \n",
    "                    jobInfo = jobData.find('div').getText(separator=\"\\n\").replace(\".\\n\", \".\\n\\n\").replace(\"\\n\\n\\n\", \"\\n\").replace(\" \\n\",\" \").replace(\"\\n \", \" \")\n",
    "                else: jobInfo = jobData.find('div').getText(separator=\"\\n\")\n",
    "\n",
    "                if localTableIndex <= 1: # if data is a description\n",
    "                    descriptionString = descriptionString + \"\\n\" + headingColList[localTableIndex] + \"\\n\" + jobInfo + \"\\n\"\n",
    "                else: # if data is a requirement\n",
    "                    requirementsString = requirementsString + \"\\n\" + headingColList[localTableIndex] + \"\\n\" + jobInfo + \"\\n\"\n",
    "                localTableIndex += 1\n",
    "                \n",
    "            description.append(descriptionString)\n",
    "            requirements.append(requirementsString)\n",
    "            \n",
    "            pageUrl.append(page)\n",
    "            jobPosition.append(allJobNames[jobIndex])\n",
    "            location.append(allLocations[jobIndex])\n",
    "            \n",
    "        jobIndex += 1\n",
    "        \n",
    "\n",
    "DataFrame = pd.DataFrame() \n",
    "DataFrame['Page Url']= pageUrl \n",
    "DataFrame['Job']= jobPosition \n",
    "DataFrame['Location'] = location\n",
    "DataFrame['Description'] = description\n",
    "DataFrame['Requirements'] = requirements\n",
    "DataFrame['Immunization'] = Immunization\n",
    "DataFrame['Economics'] = Economics\n",
    "\n",
    "Data = DataFrame.drop_duplicates() \n",
    "Data.to_csv(\"GAVI_Data.csv\")\n",
    "\n",
    "browser.quit()\n",
    "\n",
    "print('Webscraping complete')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
