{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3ce1e5c2aeab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprettify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mtable2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"table\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'results-table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tbody\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tr\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mroot_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://r4d.csod.com/ats/careersite/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "For this webscraper, the job description and requirements were combined into the same cell because they were not \n",
    "easily separated from the site's html. \n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs \n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://r4d.csod.com/ats/careersite/search.aspx?site=2&c=r4d'\n",
    "\n",
    "# ***currently no job postings for R4D, so the webscraper will not run properly!!!***\n",
    "with requests.Session() as s: \n",
    "    r = s.get(url)\n",
    "    src = r.content \n",
    "    soup = bs(src)\n",
    "    soup.prettify()\n",
    "\n",
    "    #need to access the table on the website that holds all the job links\n",
    "    table2 = soup.find(\"table\", class_ = 'results-table').find(\"tbody\").find_all(\"tr\")\n",
    "    \n",
    "    root_url = \"https://r4d.csod.com/ats/careersite/\"\n",
    "    \n",
    "    page_url = []     \n",
    "    job_position = [] \n",
    "    location = []  \n",
    "    ImmEcs = []\n",
    "    des_and_req = []  \n",
    "    organization = []\n",
    "    \n",
    "    allLinks = []\n",
    "    allJobNames = []\n",
    "    allLocations = []\n",
    "    locationDataList = []\n",
    "    \n",
    "    #first getting the data from the table\n",
    "    for data in table2:\n",
    "        job = data.find('a').text\n",
    "        allJobNames.append(job)\n",
    "        \n",
    "        #grabbing the link from the table\n",
    "        link = data.find('a')['href']\n",
    "        complete_url = root_url + link\n",
    "        allLinks.append(complete_url)\n",
    "        \n",
    "        #location data is also held in the table, so grabbing it \n",
    "        locationData = data.find('span', class_ = \"FieldValue\").getText()\n",
    "        locationDataList = locationData.split(\" | \")\n",
    "        locationString = locationDataList[2]\n",
    "        locationString = locationString.replace(\"\\xa0)\",\"\")\n",
    "        moreString = \"\"\n",
    "        #making sure we grab all the links in the table by clicking the more button\n",
    "        if \"More\" in locationString:\n",
    "            moreString = data.find('span', class_ = \"FieldValue\").find('a')['onclick']\n",
    "            moreString = moreString.replace(\"showAllLocations('\", \"\").replace(\"','\", \"\\n\").replace(\"','\", \"\\n\").replace(\"\\\\u003cbr/\\\\u003e\", \", \")\n",
    "        moreString = \"\\nMore - \" + moreString\n",
    "        locationString = locationString.replace(\"More\", moreString)\n",
    "        allLocations.append(locationString)\n",
    "    \n",
    "    \n",
    "    index = 0\n",
    "    for page in allLinks:\n",
    "        result = s.get(page)\n",
    "        page_source = result.content\n",
    "        soup = bs(page_source) \n",
    "        soup.prettify()\n",
    "\n",
    "        \n",
    "        for script in soup(['script','style']):\n",
    "            script.decompose()\n",
    "        strips = list(soup.stripped_strings)\n",
    "        strips = str(strips)\n",
    "\n",
    "    \n",
    "        immunization = ['Immunization', 'immunisation', 'vaccine', 'vaccines','vaccine-preventable diseases', 'vpd outbreak',\n",
    "            'immunization campaign', 'SIA','supplemental immunization act ivities', 'cold chain', 'GAVI','shigella', 'cholera',\n",
    "            'bcg', 'dtp', 'dpt', 'measles', 'influenza', 'conjugate vaccine']\n",
    "\n",
    "        economics = ['Economics','expenditure tracking', 'financing', \n",
    "            'value for vaccination' , 'costing', 'economic analysis','costs' , 'equity', 'cost effectiveness', 'cost-effectiveness', \n",
    "            'cost benefit analysis', 'benefit-cost analysis','cost utility analysis','budget impact analysis' , 'budget' , 'budgeting' , \n",
    "            'GAVI','funding gap','fiscal']\n",
    "\n",
    "        imm_result = any(ele in strips for ele in immunization)\n",
    "        ec_result = any(ele in strips for ele in economics)\n",
    "        \n",
    "        if imm_result or ec_result:\n",
    "            if (imm_result and ec_result): ImmEcs.append('Both')\n",
    "            elif imm_result: ImmEcs.append('Immunization')\n",
    "            else: ImmEcs.append('Economics')\n",
    "            \n",
    "            page_url.append(page) \n",
    "            job_position.append(allJobNames[index])\n",
    "            location.append(allLocations[index])\n",
    "            \n",
    "            organization.append('R4D')\n",
    "        \n",
    "            job_data = soup.find('div', class_='cs-atscs-jobdet-rtpane')\n",
    "\n",
    "            #unable to separate description and requirements again so putting them in the same column\n",
    "            desReqList= [desReqList.text.replace(\"\\n\",\" \").replace(\"      \", \" \") for desReqList in job_data.select('p, ul li')]\n",
    "            desReqList.pop()\n",
    "            popped = desReqList.pop(0)\n",
    "\n",
    "            job_text = \"\"\n",
    "            for elem in desReqList:\n",
    "                job_text += elem + \"\\n\"\n",
    "                job_text = job_text.replace(\"\\xa0\",\" \")\n",
    "            des_and_req.append(job_text)\n",
    "        index += 1\n",
    "        \n",
    "\n",
    "DataFrame = pd.DataFrame() \n",
    "DataFrame['Page Url']= page_url \n",
    "DataFrame['Job']= job_position \n",
    "DataFrame['Location'] = location\n",
    "DataFrame['Description and Requirements'] = des_and_req\n",
    "DataFrame['ImmEcs'] = ImmEcs\n",
    "DataFrame['Organization'] = organization\n",
    "\n",
    "Data = DataFrame.drop_duplicates() \n",
    "Data.to_csv(\"R4D_Data.csv\")\n",
    "\n",
    "print('Webscraping complete')           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
